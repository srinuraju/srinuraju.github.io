<h2>Project 2 — Analytics Data Modeling & Warehouse Readiness</h2>

<h3>Context</h3>
<p>
  This project focused on shaping raw and intermediate datasets into analytics-ready data models
  that could be reliably queried by analysts and downstream reporting systems.
  The emphasis was on correctness, consistency, and long-term maintainability.
</p>

<h3>What needed to be solved</h3>
<p>
  Raw datasets were difficult to query directly due to inconsistent schemas, duplicated logic,
  and unclear definitions of business metrics. Different consumers applied their own transformations,
  which led to mismatched results and low trust in reports.
</p>

<h3>How the data was modeled</h3>
<ul class="bullets">
  <li>Defined clear fact and dimension-style datasets for analytics consumption.</li>
  <li>Standardized naming conventions, data types, and grain across datasets.</li>
  <li>Used <strong>SQL</strong> to transform curated data into query-friendly structures.</li>
  <li>Published models in <strong>Amazon Athena</strong> backed by Parquet datasets in S3.</li>
</ul>

<h3>Handling data consistency</h3>
<ul class="bullets">
  <li>Established a single definition for key metrics and aggregations.</li>
  <li>Ensured joins were performed at the correct grain to avoid double counting.</li>
  <li>Validated row counts and aggregates between source and modeled layers.</li>
</ul>

<h3>Keeping data reliable</h3>
<ul class="bullets">
  <li>Schema and nullability checks for critical columns.</li>
  <li>Row-count and distribution checks to detect unexpected changes.</li>
  <li>SQL-based validation queries to verify metric correctness.</li>
</ul>

<h3>Operating in production</h3>
<ul class="bullets">
  <li>Models refreshed on a scheduled cadence aligned with upstream pipelines.</li>
  <li>Failures surfaced early to prevent stale or partial data from being queried.</li>
  <li>Clear ownership documented for maintaining and extending models.</li>
</ul>

<h3>Performance considerations</h3>
<ul class="bullets">
  <li>Partitioning aligned with common filter patterns.</li>
  <li>Column pruning leveraged through Parquet format.</li>
  <li>Avoided unnecessary joins and recalculations in frequently queried paths.</li>
</ul>

<h3>Outcome</h3>
<p>
  The modeled datasets provided a consistent foundation for analytics and reporting.
  Analysts were able to query trusted datasets without reimplementing business logic,
  improving confidence in metrics and reducing repeated ad-hoc transformations.
</p>

<h3>What I’d improve next</h3>
<ul class="bullets">
  <li>Introduce formal versioning for data models.</li>
  <li>Add automated documentation for datasets and metrics.</li>
  <li>Expand test coverage as new use cases are added.</li>
</ul>
